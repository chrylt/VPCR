#version 460
#extension GL_EXT_shader_atomic_int64 : enable
#extension GL_ARB_gpu_shader_int64 : enable
#extension GL_KHR_vulkan_glsl : enable
#include "common.glsl"

layout(set = 1, binding = 0) buffer RENDER_TARGET{
    uint64_t renderTarget[];
};

layout(set = 1, binding = 1, r32ui) uniform uimage2D depthBuffer;

layout(set = 2, binding = 0) readonly buffer BatchList{
    uint batchCount;
    uint batchList[];
};

layout(local_size_x = 1024) in;

void main(){
    drawnBatches = batchCount;

    const uint id = gl_GlobalInvocationID.x / gl_WorkGroupSize.x;
    if (id >= batchCount){
        return;
    }

    const Node batch = nodes[batchList[id]];
    const vec3 batchBBSize = vec3(batch.box.maxX, batch.box.maxY, batch.box.maxZ) - vec3(batch.box.minX, batch.box.minY, batch.box.minZ);
    const uint batchPixelExtend = getBatchPixelExtend(batch, camera.resolution, camera.projection, camera.view);
    const uint localId = gl_LocalInvocationID.x;
    const uint pointCount = batch.maskDepthCount >> 13;
    const uint workAmount = (pointCount / gl_WorkGroupSize.x) + 1;

    for (uint k = batch.pointOffset + localId * workAmount; k < batch.pointOffset + (localId + 1) * workAmount; ++k){
        if ((k - batch.pointOffset) >= pointCount){
            break;
        }

        const vec4 projected = camera.projection * camera.view * vec4(getAdaptivePointPosition(batchBBSize, vec3(batch.box.minX, batch.box.minY, batch.box.minZ), batchPixelExtend, k), 1);

        if((-projected.w <= projected.x) && (projected.x <= projected.w) &&
                (-projected.w <= projected.y) && (projected.y <= projected.w) &&
                (0.f <= projected.z) && (projected.z <= projected.w)){
            // projection is within window
            const vec2 coords = (projected.xy/projected.w * .5f + .5f) * camera.resolution;

            // compare depth now as float
            const float depth = projected.w;

            const float storedDepth = uintBitsToFloat(imageLoad(depthBuffer, ivec2(coords)).x);

            if(depth <= storedDepth * 1.01){
                // store 32-bit color to 64-bit variable to avoid overflow
                // add 8 more bit to each channel
                // alpha channel is used as a counter
                uint rgba = pointsRgba[k];
                uint r = (rgba & 0xFF);
                uint g = (rgba >> 8) & 0xFF;
                uint b = (rgba >> 16) & 0xFF;
                uint64_t rgba64 = (uint64_t(r) << 48) | (uint64_t(g) << 32) | (uint64_t(b) << 16) | 1;

	            atomicAdd(renderTarget[getPixelID(camera.resolution, uvec2(coords))], rgba64);
            }
        }
    }
}